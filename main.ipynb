{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef46b5c-9aa4-46dc-ab73-f026b3cd931c",
   "metadata": {},
   "source": [
    "# **Cadenas de Markov**\n",
    "### Proyecto Final de Estadística Aplicada a la Teoría de Decisiones II\n",
    "\n",
    "En esta notebook se desarrollará el proyecto final sobre Cadenas de Markov, cumpliendo con los siguientes objetivos:\n",
    "1. Presentar el marco teórico fundamental.\n",
    "2. Resolver problemas ilustrativos.\n",
    "3. Explorar aplicaciones en diversos ámbitos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4349db-c0f3-4fe7-86fa-f0a152b8ec22",
   "metadata": {},
   "source": [
    "# 1. **Marco Teórico**\n",
    "\n",
    "En esta sección se presentan los conceptos fundamentales de las Cadenas de Markov, sus diferencias según el tipo de tiempo (discreto o continuo) y los elementos teóricos necesarios para entender el estado estacionario.\n",
    "\n",
    "## 1.1 ¿Qué es una Cadena de Markov?\n",
    "\n",
    "Una **Cadena de Markov** es un proceso estocástico (es decir, un proceso que involucra aleatoriedad) en el cual el estado futuro depende únicamente del estado presente y no de la secuencia de eventos anteriores. En términos matemáticos:\n",
    "\n",
    "$$\n",
    "P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n,\\ X_{n-1} = x_{n-1}, \\dots, X_0 = x_0 \\bigr) \\;=\\; P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n \\bigr).\n",
    "$$\n",
    "\n",
    "Esta propiedad, conocida como **propiedad de Markov** o **memoria limitada**, permite simplificar en gran medida el análisis del proceso, ya que las probabilidades de transición únicamente necesitan considerar el estado actual.\n",
    "\n",
    "## 1.2 Diferencia entre Cadenas de Tiempo Discreto y Tiempo Continuo\n",
    "\n",
    "- **Cadenas de Markov en tiempo discreto**:  \n",
    "  En este caso, el tiempo avanza en pasos o intervalos discretos (por ejemplo, \\( n = 0, 1, 2, $\\dots$ \\). La transición de un estado a otro se produce en cada paso y viene dada por una **matriz de transición**. Es el tipo de cadena más común en muchos modelos de procesos secuenciales (como días, meses, iteraciones, etc.).\n",
    "\n",
    "- **Cadenas de Markov en tiempo continuo**:  \n",
    "  En estas cadenas, el proceso evoluciona de manera continua en el tiempo, y las transiciones pueden ocurrir en cualquier instante. Por lo general, se modelan mediante tasas de transición (matriz generador infinitesimal) y utilizan distribuciones continuas (a menudo, la distribución exponencial) para describir el tiempo que se permanece en cada estado antes de dar el salto a otro.\n",
    "\n",
    "\n",
    "## 1.3 Conceptos Fundamentales\n",
    "\n",
    "### 1.3.1 Espacio de Estados\n",
    "\n",
    "El **espacio de estados** es el conjunto de todos los valores o condiciones posibles que puede tomar el proceso. Por ejemplo, en un modelo sobre estados emocionales, el espacio podría ser \\\\(\\{ \\text{Feliz, Neutro, Triste}\\}\\\\). En un modelo de clientes, podría ser \\\\(\\{\\text{Fiel, Intermitente, Perdido}\\}\\\\).\n",
    "\n",
    "### 1.3.2 Matriz de Transición\n",
    "\n",
    "Una **matriz de transición**, denotada comúnmente como \\\\(P\\\\), contiene las probabilidades de pasar de cada estado a cada uno de los posibles estados en un solo paso de tiempo. Cada elemento \\\\(p_{ij}\\\\) de la matriz \\\\(P\\\\) representa la probabilidad de ir del estado \\\\(i\\\\) al estado \\\\(j\\\\):\n",
    "\n",
    "$$\n",
    "P \\;=\\;\n",
    "\\begin{pmatrix}\n",
    "p_{11} & p_{12} & \\cdots & p_{1m} \\\\\n",
    "p_{21} & p_{22} & \\cdots & p_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{m1} & p_{m2} & \\cdots & p_{mm}\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "donde cada fila suma 1.\n",
    "\n",
    "### 1.3.3 Probabilidad de Transición en \\\\(n\\\\) Pasos\n",
    "\n",
    "La **probabilidad de transición en \\\\(n\\\\) pasos** es la probabilidad de que el proceso pase del estado \\\\(i\\\\) al estado \\\\(j\\\\) después de \\\\(n\\\\) pasos. Se denota frecuentemente como \\\\(p_{ij}^{(n)}\\\\) y puede calcularse a partir de la \\\\(n\\\\)-ésima potencia de la matriz de transición:\n",
    "\n",
    "$$\n",
    "P^{(n)} \\;=\\; P^n \\;=\\;\n",
    "\\underbrace{P \\times P \\times \\cdots \\times P}_{n\\text{ veces}}.\n",
    "$$\n",
    "\n",
    "### 1.3.4 Estado Estacionario\n",
    "\n",
    "Un **estado estacionario** (o **distribución estacionaria**) es un vector de probabilidades \\\\(\\pi\\\\) tal que, una vez alcanzado, describe la proporción de tiempo que el proceso pasará en cada estado a largo plazo. Cumple la condición:\n",
    "\n",
    "$$\n",
    "\\pi \\, P \\;=\\; \\pi,\n",
    "$$\n",
    "\n",
    "donde \\\\(\\pi\\\\) es un vector fila cuyas entradas son las probabilidades de encontrarse en cada estado. Además, debe cumplirse:\n",
    "\n",
    "$$\n",
    "\\sum_{i} \\pi_i \\;=\\; 1\n",
    "\\quad \\text{con} \\quad \n",
    "\\pi_i \\geq 0.\n",
    "$$\n",
    "\n",
    "## 1.4 Condiciones para la Existencia de un Estado Estacionario\n",
    "\n",
    "Para que exista un **estado estacionario** único en una cadena de Markov en tiempo discreto, se requieren dos condiciones principales:\n",
    "\n",
    "1. **Irreducibilidad**: La cadena es irreducible si es posible llegar de cualquier estado a cualquier otro estado (no necesariamente en un solo paso, sino en un número finito de pasos).\n",
    "\n",
    "2. **Aperiodicidad**: La cadena es aperiódica si cada estado no se visita únicamente en intervalos regulares. En otras palabras, el máximo común divisor de los posibles tiempos de retorno a un estado es 1.\n",
    "\n",
    "Bajo estas condiciones, se garantiza la existencia de una única distribución estacionaria que describe el comportamiento a largo plazo de la cadena.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1934cb-7cc1-480a-ab73-e0ef83af818a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c052553b-5b0d-4313-b9e6-f21dec522137",
   "metadata": {},
   "source": [
    "**Autor:** Jonathan Amado (Carnet 14002285)  \n",
    "**Maestría en Investigación de Operaciones**  \n",
    "**Universidad Galileo**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b1710-d09a-4f1a-bc81-c30bdb29f1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
