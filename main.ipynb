{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef46b5c-9aa4-46dc-ab73-f026b3cd931c",
   "metadata": {},
   "source": [
    "# **Proyecto Final: Cadenas de Markov**\n",
    "\n",
    "**Estadística Aplicada a la Teoría de Decisiones II**   \n",
    "Maestría en Investigación de Operaciones  \n",
    "Universidad Galileo  \n",
    "\n",
    "Este cuaderno contiene el desarrollo completo del proyecto final sobre *Cadenas de Markov*, abordando los siguientes puntos:\n",
    "\n",
    "1. **Marco Teórico**  \n",
    "2. **Resolución de Problemas**  \n",
    "3. **Aplicaciones Reales**  \n",
    "\n",
    "Se han utilizado herramientas matemáticas, computacionales y de simulación para resolver los ejercicios planteados y analizar los resultados de forma clara y estructurada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b01da-f9f5-4ab5-9971-30b2dc010e4e",
   "metadata": {},
   "source": [
    "## **1. Marco Teórico**\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Las **Cadenas de Markov** constituyen una herramienta analítica esencial para modelar y predecir comportamientos en sistemas donde el estado futuro depende únicamente del estado presente. Su gran versatilidad permite utilizarlas en una amplia variedad de ámbitos, que van desde la economía y las finanzas hasta la ingeniería y las ciencias de la salud. En las secciones siguientes se profundizará en los fundamentos teóricos de las Cadenas de Markov, sus principales características, y las condiciones que aseguran la existencia de un estado estacionario.\n",
    "\n",
    "### **1.1 ¿Qué es una Cadena de Markov?**\n",
    "\n",
    "Una **Cadena de Markov** es un proceso estocástico (es decir, un proceso que involucra aleatoriedad) en el cual el estado futuro depende únicamente del estado presente y no de la secuencia de estados anteriores. En términos matemáticos:\n",
    "\n",
    "$$\n",
    "P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n,\\ X_{n-1} = x_{n-1}, \\dots, X_0 = x_0 \\bigr) \\;=\\; P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n \\bigr).\n",
    "$$\n",
    "\n",
    "Esta propiedad, conocida como **propiedad de Markov** o **memoria limitada**, permite simplificar en gran medida el análisis del proceso, ya que las probabilidades de transición únicamente necesitan considerar el estado actual.\n",
    "\n",
    "\n",
    "### **1.2 Diferencia entre Cadenas de Tiempo Discreto y Tiempo Continuo**\n",
    "\n",
    "- **Cadenas de Markov en tiempo discreto**:  \n",
    "  En este caso, el tiempo avanza en pasos o intervalos discretos (por ejemplo, \\( n = 0, 1, 2, \\dots \\)). La transición de un estado a otro se produce en cada paso y viene dada por una **matriz de transición**. Es el tipo de cadena más común en muchos modelos de procesos secuenciales (como días, meses, iteraciones, etc.).\n",
    "\n",
    "- **Cadenas de Markov en tiempo continuo**:  \n",
    "  En estas cadenas, el proceso evoluciona de manera continua en el tiempo, y las transiciones pueden ocurrir en cualquier instante. Por lo general, se modelan mediante tasas de transición (matriz generador infinitesimal) y utilizan distribuciones continuas (a menudo, la distribución exponencial) para describir el tiempo que se permanece en cada estado antes de dar el salto a otro.\n",
    "\n",
    "La principal diferencia está en **cómo se mide el tiempo y cómo se define el cambio de estado**, lo que también impacta en las herramientas matemáticas que se utilizan para analizarlas.\n",
    "\n",
    "### **1.3 Conceptos Fundamentales**\n",
    "\n",
    "#### **1.3.1 Espacio de Estados**\n",
    "\n",
    "El **espacio de estados** es el conjunto de todos los valores o condiciones posibles que puede tomar el proceso. Por ejemplo, en un modelo sobre estados emocionales, el espacio podría ser \\\\(\\{ \\text{Feliz, Neutro, Triste}\\}\\\\). En un modelo de clientes, podría ser \\\\(\\{\\text{Fiel, Intermitente, Perdido}\\}\\\\).\n",
    "\n",
    "#### **1.3.2 Matriz de Transición**\n",
    "\n",
    "Una **matriz de transición**, denotada comúnmente como \\\\(P\\\\), contiene las probabilidades de pasar de cada estado a cada uno de los posibles estados en un solo paso de tiempo. Cada elemento \\\\(p_{ij}\\\\) de la matriz \\\\(P\\\\) representa la probabilidad de ir del estado \\\\(i\\\\) al estado \\\\(j\\\\):\n",
    "\n",
    "$$\n",
    "P \\;=\\;\n",
    "\\begin{pmatrix}\n",
    "p_{11} & p_{12} & \\cdots & p_{1m} \\\\\n",
    "p_{21} & p_{22} & \\cdots & p_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{m1} & p_{m2} & \\cdots & p_{mm}\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "donde cada fila suma 1.\n",
    "\n",
    "#### **1.3.3 Probabilidad de Transición en \\\\(n\\\\) Pasos**\n",
    "\n",
    "La **probabilidad de transición en \\\\(n\\\\) pasos** es la probabilidad de que el proceso pase del estado \\\\(i\\\\) al estado \\\\(j\\\\) después de \\\\(n\\\\) pasos. Se denota frecuentemente como \\\\(p_{ij}^{(n)}\\\\) y puede calcularse a partir de la \\\\(n\\\\)-ésima potencia de la matriz de transición:\n",
    "\n",
    "$$\n",
    "P^{(n)} \\;=\\; P^n \\;=\\;\n",
    "\\underbrace{P \\times P \\times \\cdots \\times P}_{n\\text{ veces}}.\n",
    "$$\n",
    "\n",
    "#### **1.3.4 Estado Estacionario**\n",
    "\n",
    "Un **estado estacionario** (o **distribución estacionaria**) es un vector de probabilidades \\\\(\\pi\\\\) tal que, una vez alcanzado, describe la proporción de tiempo que el proceso pasará en cada estado a largo plazo. Cumple la condición:\n",
    "\n",
    "$$\n",
    "\\pi \\, P \\;=\\; \\pi,\n",
    "$$\n",
    "\n",
    "donde \\\\(\\pi\\\\) es un vector fila cuyas entradas son las probabilidades de encontrarse en cada estado. Además, debe cumplirse:\n",
    "\n",
    "$$\n",
    "\\sum_{i} \\pi_i \\;=\\; 1\n",
    "\\quad \\text{con} \\quad \n",
    "\\pi_i \\geq 0.\n",
    "$$\n",
    "\n",
    "\n",
    "### **1.4 Condiciones para la Existencia de un Estado Estacionario**\n",
    "\n",
    "Para que exista un **estado estacionario** único en una cadena de Markov en tiempo discreto, se requieren dos condiciones principales:\n",
    "\n",
    "1. **Irreducibilidad**: La cadena es irreducible si es posible llegar de cualquier estado a cualquier otro estado (no necesariamente en un solo paso, sino en un número finito de pasos).\n",
    "\n",
    "2. **Aperiodicidad**: La cadena es aperiódica si cada estado no se visita únicamente en intervalos regulares. En otras palabras, el máximo común divisor de los posibles tiempos de retorno a un estado es 1.\n",
    "\n",
    "3. **Cadena de tiempo discreto y espacio de estados finito**: Cuando la cadena es de tiempo discreto y tiene un número finito de estados, estas condiciones son suficientes para garantizar la existencia de un **único vector estacionario** al que la cadena converge, sin importar el estado inicial.\n",
    "\n",
    "**Resumen:**\n",
    "\n",
    "Si una cadena de Markov es **irreducible** y **aperiódica**, y tiene **espacio de estados finito**, entonces:\n",
    "\n",
    "- Existe un vector estacionario $\\pi$\n",
    "- El sistema converge a $\\pi$ con el tiempo:  \n",
    "  $$ \\lim_{n \\to \\infty} P^n = \\begin{bmatrix} \\pi \\\\ \\pi \\\\ \\vdots \\\\ \\pi \\end{bmatrix} $$\n",
    "- La distribución de probabilidad a largo plazo es independiente del estado inicial\n",
    "\n",
    "\n",
    "Bajo estas condiciones, se garantiza la existencia de una única distribución estacionaria que describe el comportamiento a largo plazo de la cadena.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f2621-5359-427a-8db6-e5513991510d",
   "metadata": {},
   "source": [
    "## **2. Resolución de Problemas**\n",
    "\n",
    "En esta sección se presentan tres ejercicios de aplicación directa de las Cadenas de Markov. Cada ejercicio aborda un escenario distinto, ilustrando los procedimientos de análisis a corto plazo, el cálculo de estados estacionarios y la modelación de sistemas.\n",
    "\n",
    "\n",
    "### **2.1 Ejercicio 1: Probabilidades a corto plazo**\n",
    "\n",
    "Una persona puede estar en tres estados emocionales cada día:\n",
    "\n",
    "- **Feliz (H)**\n",
    "- **Neutra (N)**\n",
    "- **Triste (T)**\n",
    "\n",
    "Las transiciones diarias están dadas por la siguiente matriz:\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "0.85 & 0.10 & 0.05 \\\\\n",
    "0.40 & 0.40 & 0.20 \\\\\n",
    "0.10 & 0.30 & 0.60\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Si la persona empieza el lunes en estado **feliz**, calcule la probabilidad de que esté en cada uno de los estados el **miércoles** (es decir, dos pasos después).\n",
    "\n",
    "**Objetivo**  \n",
    "- Determinar las probabilidades a corto plazo (dos pasos) para cada estado, dada una condición inicial.\n",
    "- Para ello, se debe utilizar la matriz $(P)$ y calcular $(P^2)$.\n",
    "\n",
    "**Puntos Clave**  \n",
    "- Definir correctamente el espacio de estados.\n",
    "- Utilizar la matriz de transición para calcular $(P^2)$.\n",
    "- Multiplicar la distribución inicial (100% en Feliz) por $(P^2)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f760434-0229-4798-945f-046569dd8ab8",
   "metadata": {},
   "source": [
    "**Paso 1: Definir la matriz de transición y el vector de estado inicial**\n",
    "\n",
    "Dado que la persona está **feliz** el lunes, el vector de estado inicial es:\n",
    "\n",
    "$$\n",
    "\\pi_0 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Paso 2: Calcular $\\pi_2 = \\pi_0 \\cdot P^2$**\n",
    "\n",
    "Este cálculo nos dará la probabilidad de que esté feliz, neutral o triste el miércoles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be2b1a22-8356-4b5e-a029-fc17e06926e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Estado  Probabilidad al Miércoles\n",
      "0   Feliz (H)                     0.7675\n",
      "1  Neutra (N)                     0.1400\n",
      "2  Triste (T)                     0.0925\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matriz de transición corregida según la imagen\n",
    "P = np.array([\n",
    "    [0.85, 0.10, 0.05],\n",
    "    [0.40, 0.40, 0.20],\n",
    "    [0.10, 0.30, 0.60]\n",
    "])\n",
    "\n",
    "# Vector de estado inicial: feliz\n",
    "pi_0 = np.array([1, 0, 0])\n",
    "\n",
    "# Probabilidades al miércoles (dos pasos)\n",
    "pi_2 = pi_0 @ np.linalg.matrix_power(P, 2)\n",
    "\n",
    "# Mostrar resultados\n",
    "estados = ['Feliz (H)', 'Neutra (N)', 'Triste (T)']\n",
    "df_resultado = pd.DataFrame({'Estado': estados, 'Probabilidad al Miércoles': pi_2})\n",
    "\n",
    "# Imprimir tabla\n",
    "print(df_resultado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317c51a-67a2-4c10-a295-987c05e697b3",
   "metadata": {},
   "source": [
    "**Interpretación de resultados**\n",
    "\n",
    "El vector resultante $\\pi_2$ nos indica la probabilidad de que la persona se encuentre en cada uno de los estados emocionales el **miércoles**, habiendo comenzado **feliz** el lunes.\n",
    "\n",
    "Los valores obtenidos reflejan lo siguiente:\n",
    "\n",
    "- **Feliz (H):** Esta es la probabilidad más alta, lo cual es consistente con que el modelo tiene una fuerte tendencia a permanecer en este estado (0.85 en la matriz).\n",
    "- **Neutra (N):** La probabilidad intermedia sugiere que, aunque es menos común el cambio a neutral, puede ocurrir en dos pasos con cierta frecuencia.\n",
    "- **Triste (T):** La probabilidad más baja, indicando que es menos probable que una persona inicialmente feliz llegue a estar triste en tan corto plazo.\n",
    "\n",
    "En resumen, el modelo predice una alta persistencia en el estado **feliz** en el corto plazo, con una transición moderada hacia la neutralidad y baja hacia la tristeza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56331d86-39bc-46d1-9673-cad5286d14db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
