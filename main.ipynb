{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef46b5c-9aa4-46dc-ab73-f026b3cd931c",
   "metadata": {},
   "source": [
    "# **Cadenas de Markov**\n",
    "### Proyecto Final de Estadística Aplicada a la Teoría de Decisiones II\n",
    "\n",
    "En esta notebook se desarrollará el proyecto final sobre Cadenas de Markov, cumpliendo con los siguientes objetivos:\n",
    "1. Marco teórico fundamental.\n",
    "2. Resolución de Problemas.\n",
    "3. Explorar aplicaciones en diversos ámbitos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b01da-f9f5-4ab5-9971-30b2dc010e4e",
   "metadata": {},
   "source": [
    "## **1. Marco Teórico**\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Las **Cadenas de Markov** constituyen una herramienta analítica esencial para modelar y predecir comportamientos en sistemas donde el estado futuro depende únicamente del estado presente. Su gran versatilidad permite utilizarlas en una amplia variedad de ámbitos, que van desde la economía y las finanzas hasta la ingeniería y las ciencias de la salud. En las secciones siguientes se profundizará en los fundamentos teóricos de las Cadenas de Markov, sus principales características, y las condiciones que aseguran la existencia de un estado estacionario.\n",
    "\n",
    "### **1.1 ¿Qué es una Cadena de Markov?**\n",
    "\n",
    "Una **Cadena de Markov** es un proceso estocástico (es decir, un proceso que involucra aleatoriedad) en el cual el estado futuro depende únicamente del estado presente y no de la secuencia de estados anteriores. En términos matemáticos:\n",
    "\n",
    "$$\n",
    "P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n,\\ X_{n-1} = x_{n-1}, \\dots, X_0 = x_0 \\bigr) \\;=\\; P\\bigl(X_{n+1} = x \\,\\big|\\ X_n = x_n \\bigr).\n",
    "$$\n",
    "\n",
    "Esta propiedad, conocida como **propiedad de Markov** o **memoria limitada**, permite simplificar en gran medida el análisis del proceso, ya que las probabilidades de transición únicamente necesitan considerar el estado actual.\n",
    "\n",
    "\n",
    "### **1.2 Diferencia entre Cadenas de Tiempo Discreto y Tiempo Continuo**\n",
    "\n",
    "- **Cadenas de Markov en tiempo discreto**:  \n",
    "  En este caso, el tiempo avanza en pasos o intervalos discretos (por ejemplo, \\( n = 0, 1, 2, \\dots \\)). La transición de un estado a otro se produce en cada paso y viene dada por una **matriz de transición**. Es el tipo de cadena más común en muchos modelos de procesos secuenciales (como días, meses, iteraciones, etc.).\n",
    "\n",
    "- **Cadenas de Markov en tiempo continuo**:  \n",
    "  En estas cadenas, el proceso evoluciona de manera continua en el tiempo, y las transiciones pueden ocurrir en cualquier instante. Por lo general, se modelan mediante tasas de transición (matriz generador infinitesimal) y utilizan distribuciones continuas (a menudo, la distribución exponencial) para describir el tiempo que se permanece en cada estado antes de dar el salto a otro.\n",
    "\n",
    "\n",
    "### **1.3 Conceptos Fundamentales**\n",
    "\n",
    "#### **1.3.1 Espacio de Estados**\n",
    "\n",
    "El **espacio de estados** es el conjunto de todos los valores o condiciones posibles que puede tomar el proceso. Por ejemplo, en un modelo sobre estados emocionales, el espacio podría ser \\\\(\\{ \\text{Feliz, Neutro, Triste}\\}\\\\). En un modelo de clientes, podría ser \\\\(\\{\\text{Fiel, Intermitente, Perdido}\\}\\\\).\n",
    "\n",
    "#### **1.3.2 Matriz de Transición**\n",
    "\n",
    "Una **matriz de transición**, denotada comúnmente como \\\\(P\\\\), contiene las probabilidades de pasar de cada estado a cada uno de los posibles estados en un solo paso de tiempo. Cada elemento \\\\(p_{ij}\\\\) de la matriz \\\\(P\\\\) representa la probabilidad de ir del estado \\\\(i\\\\) al estado \\\\(j\\\\):\n",
    "\n",
    "$$\n",
    "P \\;=\\;\n",
    "\\begin{pmatrix}\n",
    "p_{11} & p_{12} & \\cdots & p_{1m} \\\\\n",
    "p_{21} & p_{22} & \\cdots & p_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{m1} & p_{m2} & \\cdots & p_{mm}\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "donde cada fila suma 1.\n",
    "\n",
    "#### **1.3.3 Probabilidad de Transición en \\\\(n\\\\) Pasos**\n",
    "\n",
    "La **probabilidad de transición en \\\\(n\\\\) pasos** es la probabilidad de que el proceso pase del estado \\\\(i\\\\) al estado \\\\(j\\\\) después de \\\\(n\\\\) pasos. Se denota frecuentemente como \\\\(p_{ij}^{(n)}\\\\) y puede calcularse a partir de la \\\\(n\\\\)-ésima potencia de la matriz de transición:\n",
    "\n",
    "$$\n",
    "P^{(n)} \\;=\\; P^n \\;=\\;\n",
    "\\underbrace{P \\times P \\times \\cdots \\times P}_{n\\text{ veces}}.\n",
    "$$\n",
    "\n",
    "#### **1.3.4 Estado Estacionario**\n",
    "\n",
    "Un **estado estacionario** (o **distribución estacionaria**) es un vector de probabilidades \\\\(\\pi\\\\) tal que, una vez alcanzado, describe la proporción de tiempo que el proceso pasará en cada estado a largo plazo. Cumple la condición:\n",
    "\n",
    "$$\n",
    "\\pi \\, P \\;=\\; \\pi,\n",
    "$$\n",
    "\n",
    "donde \\\\(\\pi\\\\) es un vector fila cuyas entradas son las probabilidades de encontrarse en cada estado. Además, debe cumplirse:\n",
    "\n",
    "$$\n",
    "\\sum_{i} \\pi_i \\;=\\; 1\n",
    "\\quad \\text{con} \\quad \n",
    "\\pi_i \\geq 0.\n",
    "$$\n",
    "\n",
    "\n",
    "### **1.4 Condiciones para la Existencia de un Estado Estacionario**\n",
    "\n",
    "Para que exista un **estado estacionario** único en una cadena de Markov en tiempo discreto, se requieren dos condiciones principales:\n",
    "\n",
    "1. **Irreducibilidad**: La cadena es irreducible si es posible llegar de cualquier estado a cualquier otro estado (no necesariamente en un solo paso, sino en un número finito de pasos).\n",
    "\n",
    "2. **Aperiodicidad**: La cadena es aperiódica si cada estado no se visita únicamente en intervalos regulares. En otras palabras, el máximo común divisor de los posibles tiempos de retorno a un estado es 1.\n",
    "\n",
    "Bajo estas condiciones, se garantiza la existencia de una única distribución estacionaria que describe el comportamiento a largo plazo de la cadena.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f2621-5359-427a-8db6-e5513991510d",
   "metadata": {},
   "source": [
    "## **2. Resolución de Problemas**\n",
    "\n",
    "En esta sección se presentan tres ejercicios de aplicación directa de las Cadenas de Markov. Cada ejercicio aborda un escenario distinto, ilustrando los procedimientos de análisis a corto plazo, el cálculo de estados estacionarios y la modelación de sistemas.\n",
    "\n",
    "\n",
    "### **2.1 Ejercicio 1: Probabilidades a corto plazo**\n",
    "\n",
    "Una persona puede estar en tres estados emocionales cada día:\n",
    "\n",
    "- **Feliz (H)**\n",
    "- **Neutra (N)**\n",
    "- **Triste (T)**\n",
    "\n",
    "Las transiciones diarias están dadas por la siguiente matriz:\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "0.85 & 0.10 & 0.05 \\\\\n",
    "0.40 & 0.40 & 0.20 \\\\\n",
    "0.10 & 0.30 & 0.60\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Si la persona empieza el lunes en estado **feliz**, calcule la probabilidad de que esté en cada uno de los estados el **miércoles** (es decir, dos pasos después).\n",
    "\n",
    "**Objetivo**  \n",
    "- Determinar las probabilidades a corto plazo (dos pasos) para cada estado, dada una condición inicial.\n",
    "- Para ello, se debe utilizar la matriz $(P)$ y calcular $(P^2)$.\n",
    "\n",
    "**Puntos Clave**  \n",
    "- Definir correctamente el espacio de estados.\n",
    "- Utilizar la matriz de transición para calcular $(P^2)$.\n",
    "- Multiplicar la distribución inicial (100% en Feliz) por $(P^2)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be2b1a22-8356-4b5e-a029-fc17e06926e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz P^2:\n",
      " [[0.7675 0.14   0.0925]\n",
      " [0.52   0.26   0.22  ]\n",
      " [0.265  0.31   0.425 ]]\n",
      "\n",
      "Distribución después de 2 pasos (v2): [0.7675 0.14   0.0925]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir la matriz de transición P\n",
    "P = np.array([\n",
    "    [0.85, 0.10, 0.05],\n",
    "    [0.40, 0.40, 0.20],\n",
    "    [0.10, 0.30, 0.60]\n",
    "])\n",
    "\n",
    "# Cálculo de P^2\n",
    "P2 = P @ P  # @ es el operador de multiplicación matricial en Python\n",
    "\n",
    "# Definir la distribución inicial (inicia en estado Feliz)\n",
    "v0 = np.array([1, 0, 0])\n",
    "\n",
    "# Multiplicar v0 por P^2\n",
    "v2 = v0 @ P2\n",
    "\n",
    "print(\"Matriz P^2:\\n\", P2)\n",
    "print(\"\\nDistribución después de 2 pasos (v2):\", v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f4ca1-b32b-4b2f-a6a9-dfc7893dd287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268bc3f-f8e3-406e-ac3f-5154b7e3cafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56331d86-39bc-46d1-9673-cad5286d14db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c052553b-5b0d-4313-b9e6-f21dec522137",
   "metadata": {},
   "source": [
    "**Autor:** Jonathan Amado (Carnet 14002285)  \n",
    "**Maestría en Investigación de Operaciones**  \n",
    "**Universidad Galileo**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b1710-d09a-4f1a-bc81-c30bdb29f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si la persona empieza el lunes en estado feliz, calcule la\n",
    "probabilidad de que esté en cada uno de los estados\n",
    "el miércoles(es decir, dos pasos después)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
